{"cells":[{"cell_type":"markdown","id":"94e61ee6","metadata":{"id":"94e61ee6"},"source":["# Music VAE"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"xSsSyt9zjt79"},"id":"xSsSyt9zjt79","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"bda0ce95","metadata":{"id":"bda0ce95"},"source":["### 1. 패키지 설치"]},{"cell_type":"code","execution_count":null,"id":"40b9aa63","metadata":{"id":"40b9aa63"},"outputs":[],"source":["!pip install magenta==2.1.0"]},{"cell_type":"markdown","id":"f0796cab","metadata":{"id":"f0796cab"},"source":["### 2. 데이터 벡터화 -> TFrecord로 저장"]},{"cell_type":"code","execution_count":null,"id":"40e839bd","metadata":{"id":"40e839bd"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pathlib\n","import zipfile\n","import os\n","import pandas as pd\n","import IPython\n","import collections\n","import note_seq\n","import tensorflow.compat.v1 as tf\n","import tf_slim \n","\n","from magenta.common import merge_hparams\n","from magenta.contrib import training as contrib_training\n","from magenta.models.music_vae import MusicVAE\n","from magenta.models.music_vae import lstm_models\n","from magenta.models.music_vae import data\n","from magenta.scripts.convert_dir_to_note_sequences import convert_directory\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae.trained_model import TrainedModel"]},{"cell_type":"code","source":["#데이터 zip파일 불러오기\n","url = \"https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\"\n","dir = tf.keras.utils.get_file(origin=url, fname='/content/data.zip', \n","                                   extract=True)\n","data_dir = pathlib.Path(dir)"],"metadata":{"id":"ZfHzfMoV_G9e"},"id":"ZfHzfMoV_G9e","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#zip파일 압축해제\n","zipfile.ZipFile('/content/drive/MyDrive/MIDI_project/data.zip').extractall()"],"metadata":{"id":"GO0MpZW3_sBd"},"id":"GO0MpZW3_sBd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 경로지정\n","data_root= '/content/drive/MyDrive/MIDI_project' # 데이터 경로\n","csv_file = '/content/drive/MyDrive/MIDI_project/groove/info.csv' # midi파일 정보\n","tfrec_root = '/content/drive/MyDrive/MIDI_project/music.tfrecord'# tfrecord파일 경로"],"metadata":{"id":"jzDuQTR46n3g"},"id":"jzDuQTR46n3g","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/MIDI_project/groove/info.csv')\n","df = pd.DataFrame(df)\n","df.head(3)"],"metadata":{"id":"ALrtAG0d65aL"},"id":"ALrtAG0d65aL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["convert_directory(data_root,tfrec_root,recursive=True)"],"metadata":{"id":"pHs6-Wbx67Mu"},"id":"pHs6-Wbx67Mu","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. 모델 적용하기"],"metadata":{"id":"6DET-H1eCvOz"},"id":"6DET-H1eCvOz"},{"cell_type":"code","source":["HParams = contrib_training.HParams\n","\n","\n","class Config(collections.namedtuple(\n","    'Config',\n","    ['model', 'hparams', 'note_sequence_augmenter', 'data_converter',\n","     'train_examples_path', 'eval_examples_path', 'tfds_name'])):\n","\n","  def values(self):\n","    return self._asdict()\n","\n","Config.__new__.__defaults__ = (None,) * len(Config._fields)\n","\n","\n","def update_config(config, update_dict):\n","  config_dict = config.values()\n","  config_dict.update(update_dict)\n","  return Config(**config_dict)\n","\n","\n","CONFIG_MAP = {}\n","\n","# GrooVAE configs\n","CONFIG_MAP['groovae_4bar'] = Config(\n","    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\n","                   lstm_models.GrooveLstmDecoder()),\n","    hparams=merge_hparams(\n","        lstm_models.get_default_hparams(),\n","        HParams(\n","            batch_size=512,\n","            max_seq_len=16 * 4,  # 4 bars w/ 16 steps per bar\n","            z_size=256,\n","            enc_rnn_size=[512],\n","            dec_rnn_size=[256, 256],\n","            max_beta=0.2,\n","            free_bits=48,\n","            dropout_keep_prob=0.3,\n","        )),\n","    note_sequence_augmenter=None,\n","    data_converter=data.GrooveConverter(\n","        split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\n","        max_tensors_per_notesequence=20,\n","        pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\n","        inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\n","    tfds_name='groove/4bar-midionly',\n",")"],"metadata":{"id":"Bv7c2VnDWhhD"},"id":"Bv7c2VnDWhhD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.compat.v1.enable_eager_execution(\n","    config=None, device_policy=None, execution_mode=None\n",")\n","\n","\n","# Should not be called from within the graph to avoid redundant summaries.\n","def _trial_summary(hparams, examples_path, output_dir):\n","  \"\"\"Writes a tensorboard text summary of the trial.\"\"\"\n","\n","  examples_path_summary = tf.summary.text(\n","      'examples_path', tf.constant(examples_path, name='examples_path'),\n","      collections=[])\n","\n","  hparams_dict = hparams.values()\n","\n","  # Create a markdown table from hparams.\n","  header = '| Key | Value |\\n| :--- | :--- |\\n'\n","  keys = sorted(hparams_dict.keys())\n","  lines = ['| %s | %s |' % (key, str(hparams_dict[key])) for key in keys]\n","  hparams_table = header + '\\n'.join(lines) + '\\n'\n","\n","  hparam_summary = tf.summary.text(\n","      'hparams', tf.constant(hparams_table, name='hparams'), collections=[])\n","\n","  with tf.Session() as sess:\n","    writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n","    writer.add_summary(examples_path_summary.eval())\n","    writer.add_summary(hparam_summary.eval())\n","    writer.close()\n","\n","\n","def _get_input_tensors(dataset, config):\n","  \"\"\"Get input tensors from dataset.\"\"\"\n","  batch_size = config.hparams.batch_size\n","  iterator = tf.data.make_one_shot_iterator(dataset)\n","  (input_sequence, output_sequence, control_sequence,\n","   sequence_length) = iterator.get_next()\n","  input_sequence.set_shape(\n","      [batch_size, None, config.data_converter.input_depth])\n","  output_sequence.set_shape(\n","      [batch_size, None, config.data_converter.output_depth])\n","  if not config.data_converter.control_depth:\n","    control_sequence = None\n","  else:\n","    control_sequence.set_shape(\n","        [batch_size, None, config.data_converter.control_depth])\n","  sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n","\n","  return {\n","      'input_sequence': input_sequence,\n","      'output_sequence': output_sequence,\n","      'control_sequence': control_sequence,\n","      'sequence_length': sequence_length\n","  }\n","\n","\n","def train(train_dir,\n","          config,\n","          dataset_fn,\n","          checkpoints_to_keep=5,\n","          keep_checkpoint_every_n_hours=1,\n","          num_steps=None,\n","          master='',\n","          num_sync_workers=0,\n","          num_ps_tasks=0,\n","          task=0):\n","  \"\"\"Train loop.\"\"\"\n","  tf.gfile.MakeDirs(train_dir)\n","  is_chief = (task == 0)\n","  if is_chief:\n","    _trial_summary(\n","        config.hparams, config.train_examples_path or config.tfds_name,\n","        train_dir)\n","  with tf.Graph().as_default():\n","    with tf.device(tf.train.replica_device_setter(\n","        num_ps_tasks, merge_devices=True)):\n","\n","      model = config.model\n","      model.build(config.hparams,\n","                  config.data_converter.output_depth,\n","                  is_training=True)\n","\n","      optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n","\n","      hooks = []\n","      if num_sync_workers:\n","        optimizer = tf.train.SyncReplicasOptimizer(\n","            optimizer,\n","            num_sync_workers)\n","        hooks.append(optimizer.make_session_run_hook(is_chief))\n","\n","      grads, var_list = list(zip(*optimizer.compute_gradients(model.loss)))\n","      global_norm = tf.global_norm(grads)\n","      tf.summary.scalar('global_norm', global_norm)\n","\n","      if config.hparams.clip_mode == 'value':\n","        g = config.hparams.grad_clip\n","        clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n","      elif config.hparams.clip_mode == 'global_norm':\n","        clipped_grads = tf.cond(\n","            global_norm < config.hparams.grad_norm_clip_to_zero,\n","            lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n","                grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n","            lambda: [tf.zeros(tf.shape(g)) for g in grads])\n","      else:\n","        raise ValueError(\n","            'Unknown clip_mode: {}'.format(config.hparams.clip_mode))\n","      train_op = optimizer.apply_gradients(\n","          list(zip(clipped_grads, var_list)),\n","          global_step=model.global_step,\n","          name='train_step')\n","\n","      logging_dict = {'global_step': model.global_step,\n","                      'loss': model.loss}\n","\n","      hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n","      if num_steps:\n","        hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n","\n","      scaffold = tf.train.Scaffold(\n","          saver=tf.train.Saver(\n","              max_to_keep=checkpoints_to_keep,\n","              keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours))\n","      tf_slim.training.train(\n","          train_op=train_op,\n","          logdir=train_dir,\n","          scaffold=scaffold,\n","          hooks=hooks,\n","          save_checkpoint_secs=60,\n","          master=master,\n","          is_chief=is_chief)\n","\n","\n","def run(config_map,\n","        tf_file_reader=tf.data.TFRecordDataset,\n","        file_reader=tf.python_io.tf_record_iterator,\n","        is_training = True):\n","  \"\"\"Load model params, save config file and start trainer.\n","\n","  Args:\n","    config_map: Dictionary mapping configuration name to Config object.\n","    tf_file_reader: The tf.data.Dataset class to use for reading files.\n","    file_reader: The Python reader to use for reading files.\n","\n","  Raises:\n","    ValueError: if required flags are missing or invalid.\n","  \"\"\"\n","  config = config_map['groovae_4bar']\n","  train_dir = '/content/train'\n","  num_steps = 500\n","\n","  def dataset_fn():\n","    return data.get_dataset(\n","        config,\n","        tf_file_reader=tf_file_reader,\n","        is_training = True,\n","        cache_dataset = True)\n","\n","  if is_training == True:\n","    train(\n","        train_dir,\n","        config=config,\n","        dataset_fn=dataset_fn,\n","        num_steps=num_steps)\n","  else:\n","    print('EVALUATE')"],"metadata":{"id":"3IJn5rpMMmNQ"},"id":"3IJn5rpMMmNQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.compat.v1.disable_eager_execution()"],"metadata":{"id":"AOcqKaCjBC0J"},"id":"AOcqKaCjBC0J","execution_count":null,"outputs":[]},{"cell_type":"code","source":["run(CONFIG_MAP)"],"metadata":{"id":"Q_dx5fLRI3OC"},"id":"Q_dx5fLRI3OC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TrainedModel(config=CONFIG_MAP['groovae_4bar'],\n","                     batch_size=1,\n","                     checkpoint_dir_or_path='/content/train')\n","generate = model.sample(n=1, length=16*4, temperature=0.5)\n","note_seq.sequence_proto_to_midi_file(generate[0], '/content/generate_midi/drum_4bar.mid')"],"metadata":{"id":"9s0IF4R4Kx06"},"id":"9s0IF4R4Kx06","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qqNPPPgNMyXc"},"id":"qqNPPPgNMyXc","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"private_outputs":true,"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}